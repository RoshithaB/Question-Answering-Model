{"cells":[{"cell_type":"markdown","metadata":{"id":"U8f1Ft7U5-RZ"},"source":["# SQuAD Q&A"]},{"cell_type":"markdown","metadata":{"id":"m3_WeAAD5-Rb"},"source":["This notebook contains training scripts for models to be used for the question answering problem on the [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) v1.1 dataset, which consists on selecting a possible answer to the given question as a span of words in the given context paragraph. The newest version (v2.0) of the dataset also contains unanswerable questions, but the one on which we worked on (v1.1) does not."]},{"cell_type":"markdown","metadata":{"id":"a5MBZNJc5-Rc"},"source":["## Colab requirements"]},{"cell_type":"markdown","metadata":{"id":"f1tdJWW35-Rc"},"source":["Before restarting runtime (remember to select GPU runtime)$\\dots$"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8065,"status":"ok","timestamp":1652313618221,"user":{"displayName":"Neeharika Karanam","userId":"10667545840130301249"},"user_tz":240},"id":"P0zL0gnH5-Rd","outputId":"35aadeab-3576-4ee5-9cae-3d2bc4acb900"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'squad-question-answering'...\n","remote: Enumerating objects: 459, done.\u001b[K\n","remote: Total 459 (delta 0), reused 0 (delta 0), pack-reused 459\u001b[K\n","Receiving objects: 100% (459/459), 24.36 MiB | 18.31 MiB/s, done.\n","Resolving deltas: 100% (270/270), done.\n","\u001b[33mWARNING: Ignoring invalid distribution -cipy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -cipy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","Requirement already satisfied: numpy==1.19.2 in /usr/local/lib/python3.7/dist-packages (from -r squad-question-answering/init/base_requirements.txt (line 1)) (1.19.2)\n","Requirement already satisfied: pandas==1.1.3 in /usr/local/lib/python3.7/dist-packages (from -r squad-question-answering/init/base_requirements.txt (line 2)) (1.1.3)\n","Requirement already satisfied: matplotlib==3.3.2 in /usr/local/lib/python3.7/dist-packages (from -r squad-question-answering/init/base_requirements.txt (line 3)) (3.3.2)\n","Requirement already satisfied: scipy==1.5.3 in /usr/local/lib/python3.7/dist-packages (from -r squad-question-answering/init/base_requirements.txt (line 4)) (1.5.3)\n","Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.7/dist-packages (from -r squad-question-answering/init/base_requirements.txt (line 5)) (3.5)\n","Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.7/dist-packages (from -r squad-question-answering/init/base_requirements.txt (line 6)) (3.8.3)\n","Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r squad-question-answering/init/base_requirements.txt (line 7)) (1.7.0)\n","Requirement already satisfied: transformers==4.2.1 in /usr/local/lib/python3.7/dist-packages (from -r squad-question-answering/init/base_requirements.txt (line 8)) (4.2.1)\n","Requirement already satisfied: wandb==0.10.13 in /usr/local/lib/python3.7/dist-packages (from -r squad-question-answering/init/base_requirements.txt (line 9)) (0.10.13)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.3->-r squad-question-answering/init/base_requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.3->-r squad-question-answering/init/base_requirements.txt (line 2)) (2022.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->-r squad-question-answering/init/base_requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->-r squad-question-answering/init/base_requirements.txt (line 3)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->-r squad-question-answering/init/base_requirements.txt (line 3)) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->-r squad-question-answering/init/base_requirements.txt (line 3)) (3.0.8)\n","Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->-r squad-question-answering/init/base_requirements.txt (line 3)) (2021.10.8)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r squad-question-answering/init/base_requirements.txt (line 5)) (4.64.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r squad-question-answering/init/base_requirements.txt (line 5)) (2019.12.20)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r squad-question-answering/init/base_requirements.txt (line 5)) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r squad-question-answering/init/base_requirements.txt (line 5)) (7.1.2)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->-r squad-question-answering/init/base_requirements.txt (line 6)) (6.0.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->-r squad-question-answering/init/base_requirements.txt (line 6)) (1.15.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r squad-question-answering/init/base_requirements.txt (line 7)) (0.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r squad-question-answering/init/base_requirements.txt (line 7)) (4.2.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r squad-question-answering/init/base_requirements.txt (line 7)) (0.16.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (2.23.0)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (0.9.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (3.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (4.11.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (0.0.53)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (5.4.8)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (2.3)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (3.1.27)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (1.0.9)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (3.13)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (3.17.3)\n","Requirement already satisfied: watchdog<0.10.5,>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (0.10.4)\n","Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (3.5.4)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (0.4.0)\n","Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (5.2.0)\n","Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (1.5.12)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (5.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (3.0.4)\n","Requirement already satisfied: pathtools>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from watchdog<0.10.5,>=0.8.3->wandb==0.10.13->-r squad-question-answering/init/base_requirements.txt (line 9)) (0.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.1->-r squad-question-answering/init/base_requirements.txt (line 8)) (3.8.0)\n","\u001b[33mWARNING: Ignoring invalid distribution -cipy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n"]}],"source":["!pip install -r squad-question-answering/init/base_requirements.txt"]},{"cell_type":"code","source":["import os, sys\n","sys.path.insert(0, \"squad-question-answering\")\n","os.chdir(\"squad-question-answering\")\n","sys.path.insert(0, \"src\")\n","import os\n","import json\n","from functools import partial\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import wandb\n","import transformers\n","import collections\n","import training\n","import utils\n","import layer\n","import layer_utils\n","import config\n","import torch\n","from transformers.trainer_utils import set_seed\n","from torch.utils.data import Dataset\n","from operator import attrgetter\n","from tokenizers import BertWordPieceTokenizer, Tokenizer\n","from tokenizers.implementations import BaseTokenizer\n","from tokenizers.models import WordLevel\n","from tokenizers.normalizers import Lowercase, Sequence, Strip, StripAccents\n","from tokenizers.pre_tokenizers import Punctuation\n","from tokenizers.pre_tokenizers import Sequence as PreSequence\n","from tokenizers.pre_tokenizers import Whitespace\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Check the current configuration variables\n","[(item, getattr(config, item)) for item in dir(config) if not item.startswith(\"__\")]\n","\n","# Since we are using wandb, we have to initialize few variables so that we can use them throughout the book\n","%env WANDB_PROJECT=squad-qa\n","%env WANDB_ENTITY=wadaboa\n","%env WANDB_MODE=online\n","%env WANDB_RESUME=never\n","%env WANDB_WATCH=false\n","%env WANDB_SILENT=true\n","\n","!wandb login\n","set_seed(config.RANDOM_SEED)\n","DEVICE = utils.get_device()\n","\n","class SquadTorchDataset(Dataset):\n","    def __init__(self, df):\n","        self.df = df.copy()\n","        self.df = self.df.reset_index(drop=True)\n","    def __len__(self):\n","        return self.df.shape[0]\n","    def __getitem__(self, index):\n","        assert isinstance(index, int)\n","        question = self.df.loc[index, \"question\"]\n","        context = self.df.loc[index, \"context\"]\n","        if \"answer\" not in self.df.columns:\n","            return index, question, context\n","\n","        answer_start = self.df.loc[index, \"answer_start\"]\n","        answer_end = self.df.loc[index, \"answer_end\"]\n","        return index, question, context, answer_start, answer_end\n","    \n","class SquadDataset:\n","    JSON_RECORD_PATH = [\"data\", \"paragraphs\", \"qas\", \"answers\"]\n","\n","    def __init__(\n","        self, train_set_path=None, test_set_path=None, subset=1.0,\n","    ):\n","        # Save training and test set paths\n","        self.train_set_path = train_set_path\n","        self.test_set_path = test_set_path\n","\n","        # Process the training set\n","        self.raw_train_df = None\n","        if self.train_set_path is not None:\n","            assert os.path.exists(\n","                self.train_set_path\n","            ), \"Missing SQuAD training set .json file\"\n","            self.train_df_path = f\"{os.path.splitext(self.train_set_path)[0]}.pkl\"\n","            self.raw_train_df = self._load_dataset(\n","                self.train_set_path, self.train_df_path\n","            )\n","            if subset < 1.0:\n","                self.raw_train_df = self._get_portion(self.raw_train_df, subset)\n","\n","        # Process the test set\n","        self.raw_test_df = None\n","        if self.test_set_path:\n","            assert os.path.exists(\n","                self.test_set_path\n","            ), \"Missing SQuAD testing set .json file\"\n","            self.test_df_path = f\"{os.path.splitext(self.test_set_path)[0]}.pkl\"\n","            self.raw_test_df = self._load_dataset(self.test_set_path, self.test_df_path)\n","            self.test_has_labels = \"answer\" in self.raw_test_df.columns\n","            if subset < 1.0:\n","                self.raw_test_df = self._get_portion(self.raw_test_df, subset)\n","\n","    def _add_end_index(self, df):\n","        ans_end = []\n","        for index, row in df.iterrows():\n","            t = row.answer\n","            s = row.answer_start\n","            ans_end.append(s + len(t))\n","        df[\"answer_end\"] = ans_end\n","        return df\n","\n","    def _load_dataset(self, dataset_path, dataframe_path):\n","        if os.path.exists(dataframe_path):\n","            try:\n","                return pd.read_pickle(dataframe_path)\n","            except ValueError:\n","                pass\n","\n","        # Check if the dataset has labels or not\n","        json_file = json.loads(open(dataset_path).read())\n","        if (len(pd.json_normalize(json_file, self.JSON_RECORD_PATH[:-1]).loc[\n","                0, \"answers\"])> 0):\n","            df = self._load_dataset_with_labels(json_file)\n","        else:\n","            df = self._load_dataset_no_labels(json_file)\n","        df = df.reset_index(drop=True)\n","        df.to_pickle(dataframe_path)\n","        return df\n","\n","    def _load_dataset_with_labels(self, json_file):\n","        df = pd.json_normalize(\n","            json_file, self.JSON_RECORD_PATH, meta=[[\"data\", \"title\"]])\n","        df_questions = pd.json_normalize(\n","            json_file, self.JSON_RECORD_PATH[:-1], meta=[[\"data\", \"title\"]])\n","        df_contexts = pd.json_normalize(\n","            json_file, self.JSON_RECORD_PATH[:-2], meta=[[\"data\", \"title\"]])\n","        contexts = np.repeat(df_contexts[\"context\"].values, df_contexts.qas.str.len())\n","        contexts = np.repeat(contexts, df_questions[\"answers\"].str.len())\n","        df[\"context\"] = contexts\n","        df[\"question_id\"] = np.repeat(\n","            df_questions[\"id\"].values, df_questions[\"answers\"].str.len())\n","        df[\"question\"] = np.repeat(\n","            df_questions[\"question\"].values, df_questions[\"answers\"].str.len())\n","        df[\"context_id\"] = df[\"context\"].factorize()[0]\n","        df.rename(columns={\"data.title\": \"title\", \"text\": \"answer\"}, inplace=True)\n","        df = self._add_end_index(df)\n","        df = df.drop_duplicates()\n","        return df\n","\n","    def _load_dataset_no_labels(self, json_file):\n","        df_questions = pd.json_normalize(\n","            json_file, self.JSON_RECORD_PATH[:-1], meta=[[\"data\", \"title\"]])\n","        df_contexts = pd.json_normalize(\n","            json_file, self.JSON_RECORD_PATH[:-2], meta=[[\"data\", \"title\"]])\n","        df_questions[\"context\"] = np.repeat(\n","            df_contexts[\"context\"].values, df_contexts.qas.str.len())\n","        df_questions[\"context_id\"] = df_questions[\"context\"].factorize()[0]\n","\n","        # Rename columns\n","        df_questions.rename(\n","            columns={\"data.title\": \"title\", \"id\": \"question_id\"}, inplace=True)\n","        if \"answers\" in df_questions.columns:\n","            df_questions = df_questions.drop(\"answers\", axis=\"columns\")\n","\n","        return df_questions\n","\n","    def _get_portion(self, df, subset=1.0):\n","        amount = int(df.shape[0] * subset)\n","        random_indexes = np.random.choice(\n","            np.arange(df.shape[0]), size=amount, replace=False\n","        )\n","        return df.iloc[random_indexes].reset_index(drop=True)\n","\n","# Now we need to load the raw data \n","DATA_FOLDER = os.path.join(os.getcwd(), \"data\")\n","TRAIN_DATA_FOLDER = os.path.join(DATA_FOLDER, \"training\")\n","TRAIN_SET_PATH = os.path.join(TRAIN_DATA_FOLDER, \"training_set.json\")\n","TEST_DATA_FOLDER = os.path.join(DATA_FOLDER, \"testing\")\n","TEST_SET_PATH = os.path.join(TEST_DATA_FOLDER, \"test_set.json\")\n","\n","squad_dataset = SquadDataset(\n","    train_set_path=TRAIN_SET_PATH,\n","    test_set_path=TEST_SET_PATH,\n","    subset=config.DATA_SUBSET,\n",")\n","\n","# Now we will load the default training parameters, such as the batch size, logging frequency\n","# and where we have to save the model checkpoints\n","TRAINER_ARGS = utils.get_default_trainer_args()\n","\n","# we will load an embedding matrix using the Gensim API and use corresponding matrix as the weight block\n","embedding_model, vocab = utils.load_embedding_model(\n","    config.EMBEDDING_MODEL_NAME,\n","    embedding_dimension=config.EMBEDDING_DIMENSION,\n","    unk_token=config.UNK_TOKEN,\n","    pad_token=config.PAD_TOKEN,\n",")\n","embedding_layer = layer_utils.get_embedding_module(\n","    embedding_model, pad_id=vocab[config.PAD_TOKEN]\n",")\n","print(embedding_layer)\n","\n","#Now we will define tokenizers\n","class SquadTokenizer:\n","    ENCODING_ATTR = [\n","        \"ids\",\n","        \"type_ids\",\n","        \"tokens\",\n","        \"offsets\",\n","        \"attention_mask\",\n","        \"special_tokens_mask\",\n","        \"overflowing\",\n","        \"word_ids\",\n","    ]\n","    ENCODING_ATTR_ID = {k: i for i, k in enumerate(ENCODING_ATTR)}\n","    ATTRGETTER = attrgetter(*ENCODING_ATTR)\n","\n","    def __init__(self, device=\"cpu\"):\n","        self.device = device\n","\n","    def tokenize(self, inputs, entity=None, special=False):\n","        tokenizer = self.select_tokenizer(entity)\n","        tokenizer_padding = tokenizer.padding\n","        if not special:\n","            tokenizer.no_padding()\n","        outputs = tokenizer.encode_batch(inputs, add_special_tokens=special)\n","        tokenizer.enable_padding(**tokenizer_padding)\n","        return outputs\n","\n","    def detokenize(self, inputs, entity=None, special=True):\n","        tokenizer = self.select_tokenizer(entity)\n","        return tokenizer.decode_batch(inputs, skip_special_tokens=not special)\n","\n","    def get_pad_token_id(self):\n","        tokenizer = self.select_tokenizer(entity=\"context\")\n","        return tokenizer.padding[\"pad_id\"]\n","\n","    def find_tokenized_answer_indexes(self, offsets, starts, ends):\n","        batch_size = len(starts)\n","        max_answers = max([len(row) for row in starts])\n","        indexes = torch.full((batch_size, max_answers, 2), -100, device=self.device)\n","        for i, (start, end) in enumerate(zip(starts, ends)):\n","            for j, (s, e) in enumerate(zip(start, end)):\n","                start_index = torch.nonzero(offsets[i, :, 0] == s)\n","                end_index = torch.nonzero(offsets[i, :, 1] == e)\n","                if len(start_index) > 0 and len(end_index) > 0:\n","                    indexes[i, j, :] = torch.tensor(\n","                        [start_index[0], end_index[0]], device=self.device\n","                    )\n","        return indexes\n","\n","    def find_subword_indexes(self, word_ids):\n","        start_mask = torch.full(\n","            (len(word_ids), len(word_ids[0])), False, device=self.device)\n","        end_mask = torch.full_like(start_mask, False, device=self.device)\n","\n","        for i, word_id in enumerate(word_ids):\n","\n","            if word_id[0] != None:\n","                start_mask[i, 0] = True\n","\n","            for j in range(1, len(word_id)):\n","                if word_id[j] != word_id[j - 1]:\n","                    if word_id[j] != None:\n","                        start_mask[i, j] = True\n","                    if word_id[j - 1] != None:\n","                        end_mask[i, j] = True\n","\n","            if word_id[-1] != None:\n","                end_mask[i, -1] = True\n","\n","        return start_mask, end_mask\n","\n","    def select_tokenizer(self, entity=None):\n","        raise NotImplementedError()\n","\n","    def __call__(self, inputs):\n","        raise NotImplementedError()\n","        \n","class RecurrentSquadTokenizer(SquadTokenizer):\n","    def __init__(self, question_tokenizer, context_tokenizer, device=\"cpu\"):\n","        super().__init__(device=device)\n","        assert isinstance(question_tokenizer, Tokenizer)\n","        assert isinstance(context_tokenizer, Tokenizer)\n","        self.question_tokenizer = question_tokenizer\n","        self.context_tokenizer = context_tokenizer\n","\n","    def select_tokenizer(self, entity=None):\n","        assert entity in (\"question\", \"context\")\n","        return (\n","            self.context_tokenizer if entity == \"context\" else self.question_tokenizer)\n","\n","    def __call__(self, inputs):\n","        zipped_inputs = tuple(zip(*inputs))\n","        if len(zipped_inputs) > 3:\n","            (indexes, questions, contexts, answers_start, answers_end) = zipped_inputs\n","            testing = False\n","        else:\n","            (indexes, questions, contexts) = zipped_inputs\n","            testing = True\n","        tokenized_questions = self.tokenize(questions, entity=\"question\", special=True)\n","        tokenized_contexts = self.tokenize(contexts, entity=\"context\", special=True)\n","        qattr = list(zip(*[self.ATTRGETTER(e) for e in tokenized_questions]))\n","        cattr = list(zip(*[self.ATTRGETTER(e) for e in tokenized_contexts]))\n","        batch = {\n","            \"question_ids\": torch.tensor(\n","                qattr[self.ENCODING_ATTR_ID[\"ids\"]], device=self.device),\n","            \"question_type_ids\": torch.tensor(\n","                qattr[self.ENCODING_ATTR_ID[\"type_ids\"]], device=self.device),\n","            \"question_attention_mask\": torch.tensor(\n","                qattr[self.ENCODING_ATTR_ID[\"attention_mask\"]],\n","                dtype=torch.bool,\n","                device=self.device,),\n","            \"question_special_tokens_mask\": torch.tensor(\n","                qattr[self.ENCODING_ATTR_ID[\"special_tokens_mask\"]],\n","                dtype=torch.bool,\n","                device=self.device,),\n","            \"context_ids\": torch.tensor(\n","                cattr[self.ENCODING_ATTR_ID[\"ids\"]], device=self.device),\n","            \"context_type_ids\": torch.tensor(\n","                cattr[self.ENCODING_ATTR_ID[\"type_ids\"]], device=self.device),\n","            \"context_attention_mask\": torch.tensor(\n","                cattr[self.ENCODING_ATTR_ID[\"attention_mask\"]],\n","                dtype=torch.bool,\n","                device=self.device,),\n","            \"context_special_tokens_mask\": torch.tensor(\n","                cattr[self.ENCODING_ATTR_ID[\"special_tokens_mask\"]],\n","                dtype=torch.bool,\n","                device=self.device,),\n","            \"context_offsets\": torch.tensor(\n","                cattr[self.ENCODING_ATTR_ID[\"offsets\"]], device=self.device),\n","            \"indexes\": torch.tensor(indexes, dtype=torch.long, device=self.device),\n","        }\n","\n","        # Add custom info to the batch dict\n","        batch[\"context_offsets\"] = torch.where(\n","            batch[\"context_attention_mask\"].unsqueeze(-1).repeat(1, 1, 2),\n","            batch[\"context_offsets\"],\n","            -100,)\n","        batch[\"question_lenghts\"] = torch.count_nonzero(\n","            batch[\"question_attention_mask\"], dim=1)\n","        batch[\"context_lenghts\"] = torch.count_nonzero(\n","            batch[\"context_attention_mask\"], dim=1)\n","        (\n","            batch[\"subword_start_mask\"],\n","            batch[\"subword_end_mask\"],\n","        ) = self.find_subword_indexes(cattr[self.ENCODING_ATTR_ID[\"word_ids\"]])\n","\n","        if not testing:\n","            batch[\"answers\"] = self.find_tokenized_answer_indexes(\n","                batch[\"context_offsets\"], answers_start, answers_end\n","            )\n","        return batch\n","\n","def get_recurrent_tokenizer(vocab, max_context_tokens, unk_token, pad_token, device=\"cpu\"):\n","    question_tokenizer = Tokenizer(WordLevel(vocab, unk_token=unk_token))\n","    question_tokenizer.normalizer = Sequence([StripAccents(), Lowercase(), Strip()])\n","    question_tokenizer.pre_tokenizer = PreSequence([Whitespace(), Punctuation()])\n","    question_tokenizer.enable_padding(\n","        direction=\"right\", pad_id=vocab[pad_token], pad_type_id=1, pad_token=pad_token)\n","    context_tokenizer = Tokenizer(WordLevel(vocab, unk_token=unk_token))\n","    context_tokenizer.normalizer = Sequence([StripAccents(), Lowercase(), Strip()])\n","    context_tokenizer.pre_tokenizer = PreSequence([Whitespace(), Punctuation()])\n","    context_tokenizer.enable_padding(\n","        direction=\"right\",\n","        pad_id=vocab[pad_token],\n","        pad_type_id=1,\n","        pad_token=pad_token,)\n","    context_tokenizer.enable_truncation(max_context_tokens)\n","    return RecurrentSquadTokenizer(question_tokenizer, context_tokenizer, device=device)\n","\n","\n","recurrent_tokenizer = get_recurrent_tokenizer(\n","    vocab,\n","    config.MAX_CONTEXT_TOKENS,\n","    config.UNK_TOKEN,\n","    config.PAD_TOKEN,\n","    device=DEVICE,)\n","\n","#we will now create a class called as SquadDataManager which acts as a pre-processor\n","class SquadDataManager:\n","    def __init__(self, dataset, tokenizer, val_split=0.2, device=\"cpu\"):\n","        assert isinstance(dataset, SquadDataset)\n","        assert isinstance(tokenizer, SquadTokenizer)\n","        self.dataset = dataset\n","        self.tokenizer = tokenizer\n","        self.val_split = val_split\n","        self.device = device\n","\n","        # Preprocess the raw train dataset and perform train/val split\n","        self.train_dataset, self.val_dataset = None, None\n","        if self.dataset.raw_train_df is not None:\n","            train_df = self.dataset.raw_train_df.copy()\n","            train_df = self._remove_lost_answers(train_df)\n","            train_df = self._group_answers(train_df)\n","            self.whole_dataset = SquadTorchDataset(train_df)\n","            self.train_df, self.val_df = self._train_val_split(train_df, self.val_split)\n","            self.train_dataset = SquadTorchDataset(self.train_df)\n","            self.val_dataset = SquadTorchDataset(self.val_df)\n","\n","        # Preprocess the raw test dataset\n","        self.test_dataset = None\n","        if self.dataset.raw_test_df is not None:\n","            test_df = self.dataset.raw_test_df.copy()\n","            self.test_df = self._group_answers(test_df)\n","            self.test_dataset = SquadTorchDataset(self.test_df)\n","\n","    def _remove_lost_answers(self, df):\n","        tokenized_contexts = self.tokenizer.tokenize(\n","            df[\"context\"].tolist(), \"context\", special=False)\n","        lost_truncated, lost_dirty = self._lost_answers_indexes(df, tokenized_contexts)\n","        to_remove = lost_truncated + lost_dirty\n","        clean_df = df.drop(to_remove)\n","        assert len(clean_df) == len(df) - len(to_remove), (\n","            f\"Before {len(df)}, \" f\"after {len(clean_df)}, \" f\"removed {len(to_remove)}\")\n","        return clean_df\n","\n","    def _lost_answers_indexes(self, df, tokenized_contexts):\n","        whole_answers_start = df[\"answer_start\"].tolist()\n","        whole_answers_end = df[\"answer_end\"].tolist()\n","        lost_dirty, lost_truncated = [], []\n","        for i, (c, s, e) in enumerate(\n","            zip(tokenized_contexts, whole_answers_start, whole_answers_end)):\n","            mask = (\n","                torch.tensor(c.attention_mask, device=self.device).bool()\n","                & ~torch.tensor(c.special_tokens_mask, device=self.device).bool())\n","            offsets = torch.tensor(c.offsets, device=self.device)[mask]\n","            start_index = torch.nonzero(offsets[:, 0] == s)\n","            end_index = torch.nonzero(offsets[:, 1] == e)\n","            if len(start_index) == 0 or len(end_index) == 0:\n","                if s > offsets[-1, 0] or e > offsets[-1, 1]:\n","                    lost_truncated.append(i)\n","                else:\n","                    lost_dirty.append(i)\n","\n","        return lost_truncated, lost_dirty\n","\n","    def _group_answers(self, df):\n","        if \"answer\" not in df.columns:\n","            return df\n","\n","        return (\n","            df.groupby([\"question_id\", \"question\", \"title\", \"context_id\", \"context\"])\n","            .agg({\"answer\": list, \"answer_start\": list, \"answer_end\": list})\n","            .reset_index()\n","        )\n","\n","    def _train_val_split(self, df, val_split):\n","        val_size = round(df.shape[0] * val_split)\n","        val_actual_size = 0\n","        val_keys = []\n","        for t, n in df[\"title\"].value_counts().to_dict().items():\n","            if val_actual_size + n > val_size:\n","                break\n","            val_keys.append(t)\n","            val_actual_size += n\n","\n","        # Build the train and validation DataFrames\n","        train_df = df[~df[\"title\"].isin(val_keys)].reset_index(drop=True)\n","        val_df = df[df[\"title\"].isin(val_keys)].reset_index(drop=True)\n","        return train_df, val_df\n","\n","recurrent_dm = SquadDataManager(\n","    squad_dataset, recurrent_tokenizer, val_split=config.VAL_SPLIT, device=DEVICE)\n","\n","#We will first build the QA baseline model from scratch \n","#given below is the absract QA model \n","class QAModel(nn.Module):\n","    IGNORE_LAYERS = []\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def count_parameters(self):\n","        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","    def state_dict(self):\n","        st_dict = super().state_dict()\n","        keys = set(st_dict.keys())\n","        for l in self.IGNORE_LAYERS:\n","            for k in st_dict.keys():\n","                if k.startswith(l):\n","                    keys.remove(k)\n","        return collections.OrderedDict({k: v for k, v in st_dict.items() if k in keys})\n","\n","    def load_state_dict(self, state_dict, strict=False):\n","        return super().load_state_dict(state_dict, strict=strict)\n","    \n","class QABaselineModel(QAModel):\n","    IGNORE_LAYERS = [\"embedding.weight\"]\n","    def __init__(\n","        self,\n","        embedding_module,\n","        hidden_size=100,\n","        num_recurrent_layers=2,\n","        bidirectional=False,\n","        dropout_rate=0.2,\n","        device=\"cpu\",):\n","        super().__init__()\n","        self.embedding = embedding_module\n","        self.embedding_dimension = embedding_module.weight.shape[-1]\n","        self.projection = nn.Linear(self.embedding_dimension, hidden_size)\n","        self.recurrent_module = layer.LSTM(\n","            hidden_size,\n","            hidden_size,\n","            batch_first=True,\n","            num_layers=num_recurrent_layers,\n","            bidirectional=bidirectional,\n","            dropout=dropout_rate,)\n","        out_dim = hidden_size if not bidirectional else 2 * hidden_size\n","        self.out_lstm = layer.LSTM(\n","            out_dim, hidden_size, batch_first=True, bidirectional=bidirectional)\n","        self.output_layer = layer.QAOutput(\n","            out_dim,\n","            1,\n","            dropout_rate=dropout_rate,\n","            classifier_bias=True,\n","            device=device,)\n","        self.device = device\n","        self.to(self.device)\n","\n","    def forward(self, **inputs):\n","        embedded_questions = self.embedding(inputs[\"question_ids\"])\n","        embedded_contexts = self.embedding(inputs[\"context_ids\"])\n","\n","        hidden_questions = self.projection(embedded_questions)\n","        hidden_contexts = self.projection(embedded_contexts)\n","\n","        padded_questions, _ = self.recurrent_module(\n","            hidden_questions, inputs[\"question_lenghts\"])\n","        padded_contexts, _ = self.recurrent_module(\n","            hidden_contexts, inputs[\"context_lenghts\"])\n","        average_questions = padded_questions.sum(dim=1) / inputs[\n","            \"question_lenghts\"].view(-1, 1)\n","        start_input = padded_contexts * average_questions.unsqueeze(1).repeat(\n","            1, padded_contexts.shape[1], 1)\n","        end_input, _ = self.out_lstm(start_input, inputs[\"context_lenghts\"])\n","        return self.output_layer(start_input, end_input, **inputs)\n","\n","%env WANDB_RUN_GROUP=baseline\n","baseline_run_name = utils.get_run_name()\n","baseline_args = partial(\n","    TRAINER_ARGS,\n","    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{baseline_run_name}\",\n","    num_train_epochs=30,\n","    per_device_train_batch_size=128,\n","    per_device_eval_batch_size=128,\n",")\n","\n","baseline_model = QABaselineModel(embedding_layer, device=DEVICE)\n","print(f\"The baseline model has {baseline_model.count_parameters()} parameters\")\n","\n","baseline_optimizer = optim.Adam(baseline_model.parameters(), lr=1e-3)\n","baseline_lr_scheduler = transformers.get_constant_schedule(baseline_optimizer)\n","baseline_trainer = training.SquadTrainer(\n","    model=baseline_model,\n","    args=baseline_args(run_name=baseline_run_name),\n","    data_collator=recurrent_dm.tokenizer,\n","    train_dataset=recurrent_dm.train_dataset,\n","    eval_dataset=recurrent_dm.val_dataset,\n","    optimizers=(baseline_optimizer, baseline_lr_scheduler),\n",")\n","\n","wandb.init(project=\"QA\", entity=\"nkaranam\")\n","baseline_trainer.train()\n","baseline_test_output = baseline_trainer.predict(recurrent_dm.test_dataset)\n","baseline_test_output.metrics\n","baseline_answers_path = \"results/answers/baseline.json\"\n","utils.save_answers(baseline_answers_path, baseline_test_output.predictions[-1])\n","wandb.save(baseline_answers_path);\n","wandb.finish()\n","\n","#Now we will run the BIDAF model and store the results\n","%env WANDB_RUN_GROUP=bidaf\n","bidaf_run_name = utils.get_run_name()\n","bidaf_args = partial(\n","    TRAINER_ARGS,\n","    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{bidaf_run_name}\",\n","    num_train_epochs=18, #18\n","    per_device_train_batch_size=60,\n","    per_device_eval_batch_size=60,\n",")\n","\n","class QABiDAFModel(QAModel):\n","    IGNORE_LAYERS = [\"word_embedding.weight\"]\n","    def __init__(\n","        self,\n","        embedding_module,\n","        hidden_size=100,\n","        highway_depth=2,\n","        dropout_rate=0.2,\n","        device=\"cpu\",):\n","        super().__init__()\n","        self.word_embedding = embedding_module\n","        self.word_embedding_dimension = embedding_module.weight.shape[-1]\n","        self.projection = nn.Linear(\n","            self.word_embedding_dimension, hidden_size, bias=False)\n","        self.highway_depth = highway_depth\n","        self.highway = layer_utils.get_highway(\n","            self.highway_depth, hidden_size, device=device)\n","        self.dropout_rate = dropout_rate\n","        self.dropout = nn.Dropout(self.dropout_rate)\n","        self.contextual_embedding = layer.LSTM(\n","            hidden_size,\n","            hidden_size,\n","            batch_first=True,\n","            num_layers=1,\n","            bidirectional=True,)\n","        self.attention = layer.AttentionFlow(2 * hidden_size, device=device)\n","        self.modeling_layer = layer.LSTM(\n","            8 * hidden_size,\n","            hidden_size,\n","            batch_first=True,\n","            bidirectional=True,\n","            num_layers=2,\n","            dropout=self.dropout_rate,)\n","        self.out_lstm = layer.LSTM(\n","            2 * hidden_size,\n","            hidden_size,\n","            batch_first=True,\n","            bidirectional=True,)\n","        self.output_layer = layer.QAOutput(\n","            10 * hidden_size,\n","            1,\n","            dropout_rate=self.dropout_rate,\n","            classifier_bias=False,\n","            device=device,)\n","        self.device = device\n","        self.to(self.device)\n","\n","    def forward(self, **inputs):\n","        # Extract masks and lenghts from the inputs\n","        questions_mask = inputs[\"question_attention_mask\"]\n","        contexts_mask = inputs[\"context_attention_mask\"]\n","        questions_length = inputs[\"question_lenghts\"]\n","        contexts_length = inputs[\"context_lenghts\"]\n","\n","        embedded_questions = self.dropout(self.word_embedding(inputs[\"question_ids\"]))\n","        embedded_contexts = self.dropout(self.word_embedding(inputs[\"context_ids\"]))\n","\n","        hidden_questions = self.projection(embedded_questions)\n","        hidden_contexts = self.projection(embedded_contexts)\n","\n","        highway_questions = self.highway(hidden_questions)\n","        highway_contexts = self.highway(hidden_contexts)\n","\n","        contextual_questions, _ = self.contextual_embedding(\n","            highway_questions, questions_length)\n","        contextual_contexts, _ = self.contextual_embedding(\n","            highway_contexts, contexts_length)\n","\n","        query_aware_contexts = self.attention(\n","            contextual_questions, contextual_contexts, questions_mask, contexts_mask)\n","        modeling, _ = self.modeling_layer(query_aware_contexts, contexts_length)\n","        m2, _ = self.out_lstm(modeling, contexts_length)\n","        return self.output_layer(\n","            torch.cat([query_aware_contexts, modeling], dim=-1),\n","            torch.cat([query_aware_contexts, m2], dim=-1),\n","            **inputs,)\n","    \n","#Initialize the model\n","bidaf_model = QABiDAFModel(embedding_layer, device=DEVICE)\n","print(f\"The BiDAF model has {bidaf_model.count_parameters()} parameters\")\n","bidaf_optimizer = optim.Adadelta(bidaf_model.parameters(), lr=0.5)\n","bidaf_lr_scheduler = transformers.get_constant_schedule(bidaf_optimizer)\n","bidaf_trainer = training.SquadTrainer(\n","    model=bidaf_model,\n","    args=bidaf_args(run_name=bidaf_run_name),\n","    data_collator=recurrent_dm.tokenizer,\n","    train_dataset=recurrent_dm.train_dataset,\n","    eval_dataset=recurrent_dm.val_dataset,\n","    optimizers=(bidaf_optimizer, bidaf_lr_scheduler),)\n","\n","import wandb\n","wandb.init(project=\"QA\", entity=\"nkaranam\")\n","bidaf_trainer.train()\n","bidaf_test_output = bidaf_trainer.predict(recurrent_dm.test_dataset)\n","bidaf_test_output.metrics\n","\n","bidaf_answers_path = \"results/answers/bidaf.json\"\n","utils.save_answers(bidaf_answers_path, bidaf_test_output.predictions[-1])\n","wandb.save(bidaf_answers_path);\n","wandb.finish()\n","\n","#Now that we are done with playing around with the baseline models,\n","#we will now use Transformers-based modules\n","\n","#We need to define a new tokenizer for the transformer based module because\n","# the tokenization is different for transformer models\n","class TransformerSquadTokenizer(SquadTokenizer):\n","    def __init__(self, tokenizer, device=\"cpu\"):\n","        super().__init__(device=device)\n","        assert isinstance(tokenizer, Tokenizer) or isinstance(tokenizer, BaseTokenizer)\n","        self.tokenizer = tokenizer\n","\n","    def select_tokenizer(self, entity=None):\n","        return self.tokenizer\n","\n","    def __call__(self, inputs):\n","        zipped_inputs = tuple(zip(*inputs))\n","        if len(zipped_inputs) > 3:\n","            (indexes, questions, contexts, answers_start, answers_end) = zipped_inputs\n","            testing = False\n","        else:\n","            (indexes, questions, contexts) = zipped_inputs\n","            testing = True\n","\n","        tokenized = self.tokenize(list(zip(questions, contexts)), special=True)\n","        attr = list(zip(*[self.ATTRGETTER(e) for e in tokenized]))\n","\n","        # Create the batch dictionary with encoding info\n","        batch = {\n","            \"context_ids\": torch.tensor(\n","                attr[self.ENCODING_ATTR_ID[\"ids\"]], device=self.device),\n","            \"context_type_ids\": torch.tensor(\n","                attr[self.ENCODING_ATTR_ID[\"type_ids\"]], device=self.device),\n","            \"attention_mask\": torch.tensor(\n","                attr[self.ENCODING_ATTR_ID[\"attention_mask\"]],\n","                dtype=torch.bool,\n","                device=self.device,),\n","            \"special_tokens_mask\": torch.tensor(\n","                attr[self.ENCODING_ATTR_ID[\"special_tokens_mask\"]],\n","                dtype=torch.bool,\n","                device=self.device,),\n","            \"offsets\": torch.tensor(\n","                attr[self.ENCODING_ATTR_ID[\"offsets\"]], device=self.device),\n","            \"indexes\": torch.tensor(indexes, dtype=torch.long, device=self.device),\n","        }\n","\n","        # Add custom info to the batch dict\n","        batch[\"context_attention_mask\"] = (\n","            batch[\"context_type_ids\"].bool() & ~batch[\"special_tokens_mask\"])\n","        batch[\"context_offsets\"] = torch.where(\n","            batch[\"context_attention_mask\"].unsqueeze(-1).repeat(1, 1, 2),\n","            batch[\"offsets\"],\n","            -100,)\n","        (\n","            batch[\"subword_start_mask\"],\n","            batch[\"subword_end_mask\"],\n","        ) = self.find_subword_indexes(attr[self.ENCODING_ATTR_ID[\"word_ids\"]])\n","\n","        if not testing:\n","            batch[\"answers\"] = self.find_tokenized_answer_indexes(\n","                batch[\"context_offsets\"], answers_start, answers_end)\n","        return batch\n","\n","transformer_tokenizer = get_transformer_tokenizer(\n","    config.BERT_VOCAB_PATH, config.MAX_BERT_TOKENS, device=DEVICE)\n","transformer_dm = SquadDataManager(\n","    squad_dataset, transformer_tokenizer, val_split=config.VAL_SPLIT, device=DEVICE)\n","\n","#We will now run the BERT Model\n","class QABertModel(QAModel):\n","    \n","    BERT_OUTPUT_SIZE = 768\n","    MODEL_TYPE = \"bert-base-uncased\"\n","\n","    def __init__(self, dropout_rate=0.2, device=\"cpu\"):\n","        super().__init__()\n","\n","        # BERT model\n","        self.bert_model = self.get_model()\n","        self.out_lstm = layer.LSTM(\n","            self.BERT_OUTPUT_SIZE,\n","            self.BERT_OUTPUT_SIZE,\n","            batch_first=True,\n","            bidirectional=False,)\n","        self.output_layer = layer.QAOutput(\n","            self.BERT_OUTPUT_SIZE,\n","            1,\n","            dropout_rate=dropout_rate,\n","            classifier_bias=False,\n","            device=device,)\n","        self.device = device\n","        self.to(self.device)\n","\n","    def get_model(self):\n","        return transformers.BertModel.from_pretrained(self.MODEL_TYPE)\n","\n","    def get_model_inputs(self, **inputs):\n","        return {\n","            \"input_ids\": inputs[\"context_ids\"],\n","            \"token_type_ids\": inputs[\"context_type_ids\"],\n","            \"attention_mask\": inputs[\"attention_mask\"],\n","        }\n","\n","    def forward(self, **inputs):\n","        bert_inputs = self.get_model_inputs(**inputs)\n","        bert_outputs = self.bert_model(**bert_inputs)[0]\n","        end_input, _ = self.out_lstm(\n","            bert_outputs,\n","            torch.tensor(bert_outputs.shape[1], device=self.device).repeat(\n","                bert_outputs.shape[0]),)\n","        outputs = self.output_layer(bert_outputs, end_input, **inputs)\n","        return outputs\n","    \n","%env WANDB_RUN_GROUP=bert\n","bert_run_name = utils.get_run_name()\n","bert_args = partial(\n","    TRAINER_ARGS,\n","    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{bert_run_name}\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n",")\n","bert_model = QABertModel(device=DEVICE)\n","bert_optimizer = optim.Adam(bert_model.parameters(), lr=5e-5)\n","bert_lr_scheduler = transformers.get_constant_schedule(bert_optimizer)\n","bert_trainer = training.SquadTrainer(\n","    model=bert_model,\n","    args=bert_args(run_name=bert_run_name),\n","    data_collator=transformer_dm.tokenizer,\n","    train_dataset=transformer_dm.train_dataset,\n","    eval_dataset=transformer_dm.val_dataset,\n","    optimizers=(bert_optimizer, bert_lr_scheduler),)\n","\n","import wandb\n","wandb.init(project=\"QA\", entity=\"nkaranam\")\n","bert_trainer.train()\n","bert_test_output = bert_trainer.predict(transformer_dm.test_dataset)\n","bert_test_output.metrics\n","bert_answers_path = \"results/answers/bert.json\"\n","utils.save_answers(bert_answers_path, bert_test_output.predictions[-1])\n","wandb.save(bert_answers_path);\n","wandb.finish()\n","\n","#Now we will run the DistilBERT, Given below is the class for distilBERT\n","class QADistilBertModel(QABertModel):\n","    MODEL_TYPE = \"distilbert-base-uncased\"\n","    def __init__(self, dropout_rate=0.2, device=\"cpu\"):\n","        super().__init__(dropout_rate=dropout_rate, device=device)\n","    def get_model(self):\n","        return transformers.DistilBertModel.from_pretrained(self.MODEL_TYPE)\n","\n","    def get_model_inputs(self, **inputs):\n","        return {\n","            \"input_ids\": inputs[\"context_ids\"],\n","            \"attention_mask\": inputs[\"attention_mask\"],\n","        }\n","\n","%env WANDB_RUN_GROUP=distilbert\n","distilbert_run_name = utils.get_run_name()\n","distilbert_args = partial(\n","    TRAINER_ARGS,\n","    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{distilbert_run_name}\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n",")\n","distilbert_model = QADistilBertModel(device=DEVICE)\n","distilbert_optimizer = optim.Adam(distilbert_model.parameters(), lr=5e-5)\n","distilbert_lr_scheduler = transformers.get_constant_schedule(distilbert_optimizer)\n","distilbert_trainer = training.SquadTrainer(\n","    model=distilbert_model,\n","    args=distilbert_args(run_name=distilbert_run_name),\n","    data_collator=transformer_dm.tokenizer,\n","    train_dataset=transformer_dm.train_dataset,\n","    eval_dataset=transformer_dm.val_dataset,\n","    optimizers=(distilbert_optimizer, distilbert_lr_scheduler),\n",")\n","import wandb\n","\n","wandb.init(project=\"QA\", entity=\"nkaranam\")\n","distilbert_trainer.train()\n","distilbert_test_output = distilbert_trainer.predict(transformer_dm.test_dataset)\n","distilbert_test_output.metrics\n","distilbert_answers_path = \"results/answers/distilbert.json\"\n","utils.save_answers(distilbert_answers_path, distilbert_test_output.predictions[-1])\n","wandb.save(distilbert_answers_path);\n","wandb.finish()\n","\n","#Now we will use ELECTRA as a transformer\n","class QAElectraModel(QABertModel):\n","    MODEL_TYPE = \"google/electra-base-discriminator\"\n","    def __init__(self, dropout_rate=0.2, device=\"cpu\"):\n","        super().__init__(dropout_rate=dropout_rate, device=device)\n","    def get_model(self):\n","        return transformers.ElectraModel.from_pretrained(self.MODEL_TYPE)\n","    \n","%env WANDB_RUN_GROUP=electra\n","electra_run_name = utils.get_run_name()\n","electra_args = partial(\n","    TRAINER_ARGS,\n","    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{electra_run_name}\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,)\n","\n","electra_model = QAElectraModel(device=DEVICE)\n","electra_optimizer = optim.Adam(electra_model.parameters(), lr=5e-5)\n","electra_lr_scheduler = transformers.get_constant_schedule(electra_optimizer)\n","electra_trainer = training.SquadTrainer(\n","    model=electra_model,\n","    args=electra_args(run_name=electra_run_name),\n","    data_collator=transformer_dm.tokenizer,\n","    train_dataset=transformer_dm.train_dataset,\n","    eval_dataset=transformer_dm.val_dataset,\n","    optimizers=(electra_optimizer, electra_lr_scheduler),)\n","\n","import wandb\n","wandb.init(project=\"QA\", entity=\"nkaranam\")\n","electra_trainer.train()\n","electra_test_output = electra_trainer.predict(transformer_dm.test_dataset)\n","electra_test_output.metrics\n","electra_answers_path = \"results/answers/electra.json\"\n","utils.save_answers(electra_answers_path, electra_test_output.predictions[-1])\n","wandb.save(electra_answers_path);\n","wandb.finish()\n","\n","\n"],"metadata":{"id":"K259tdLE2INZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Error analysis\n","\n","import sys\n","sys.path.insert(0, \"src\")\n","from transformers.trainer_utils import set_seed\n","import config\n","%load_ext autoreload\n","%autoreload 2\n","set_seed(config.RANDOM_SEED)\n","with open('results/wrong/baseline.json') as f:\n","    baseline_errors = json.load(f)\n","with open('results/wrong/bidaf.json') as f:\n","    bidaf_errors = json.load(f)\n","with open('results/wrong/bert.json') as f:\n","    bert_errors = json.load(f)\n","with open('results/wrong/distilbert.json') as f:\n","    distilbert_errors = json.load(f)\n","with open('results/wrong/electra.json') as f:\n","    electra_errors = json.load(f)\n","\n","print(f\"The Baseline model makes {len(baseline_errors)} errors\")\n","print(f\"The BiDAF model makes {len(bidaf_errors)} errors\")\n","print(f\"The BERT model makes {len(bert_errors)} errors\")\n","print(f\"The DistilBERT model makes {len(distilbert_errors)} errors\")\n","print(f\"The ELECTRA model makes {len(electra_errors)} errors\")\n","\n","for e in random_best_common_errors:\n","    context = electra_errors[e][\"context\"]\n","    question = electra_errors[e][\"question\"]\n","    answers = electra_errors[e][\"answers\"]\n","    electra_pred = electra_errors[e][\"prediction\"]\n","    bidaf_pred = bidaf_errors[e][\"prediction\"]\n","    print(f\"Context: {context}\")\n","    print(f\"Question: {question}\")\n","    print(f\"Answers: {answers}\")\n","    print(f\"Predictions: [ELECTRA] {electra_pred} [BiDAF] {bidaf_pred}\")\n","    print()"],"metadata":{"id":"qZhazbTXLddq"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}